{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3730fef8",
   "metadata": {},
   "source": [
    "# IG Toy Slot — KL-bounded updates under RTP/Hit guardrails\n",
    "\n",
    "這份 notebook 展示：\n",
    "1. 基線 paytable 與 KPI（RTP/Hit/Var）\n",
    "2. KL 有界小步（鏡像下降風味）導航，提升 Var\n",
    "3. Monte Carlo 模擬交叉驗證\n",
    "4. 生成 Excel 鏡像與圖表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00255a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "payouts = np.array([0.0, 0.5, 1.0, 2.0, 5.0, 10.0, 25.0, 50.0], dtype=float)\n",
    "p0 = np.array([0.68, 0.0896, 0.1024, 0.064, 0.0384, 0.016, 0.0064, 0.0032], dtype=float)\n",
    "p0 = p0 / p0.sum()\n",
    "rtp_target, rtp_tol = 0.95, 0.005\n",
    "hit_target, hit_tol = 0.32, 0.02\n",
    "\n",
    "def metrics(p):\n",
    "    rtp = float(p @ payouts)\n",
    "    hit = float((payouts>0).astype(float) @ p)\n",
    "    e2 = float(p @ (payouts**2))\n",
    "    var = e2 - rtp**2\n",
    "    return rtp, hit, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtp0, hit0, var0 = metrics(p0)\n",
    "rtp0, hit0, var0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mu, w_hit, w_var = 1.0, 1.0, 0.25\n",
    "var_target = var0 * 1.2\n",
    "ind_win = (payouts>0).astype(float)\n",
    "\n",
    "def objective_and_grad(p):\n",
    "    rtp, hit, var = metrics(p)\n",
    "    dmu = payouts\n",
    "    dhit = ind_win\n",
    "    dvar = payouts**2 - 2 * rtp * payouts\n",
    "    obj = (w_mu*(rtp-rtp_target)**2 +\n",
    "           w_hit*(hit-hit_target)**2 +\n",
    "           w_var*(var-var_target)**2)\n",
    "    grad = (2*w_mu*(rtp-rtp_target)*dmu +\n",
    "            2*w_hit*(hit-hit_target)*dhit +\n",
    "            2*w_var*(var-var_target)*dvar)\n",
    "    return obj, grad, rtp, hit, var\n",
    "\n",
    "def md_step(p, grad, lr):\n",
    "    x = np.log(np.clip(p, 1e-12, 1.0)) - lr*grad\n",
    "    x -= x.max()\n",
    "    p_new = np.exp(x); p_new = p_new / p_new.sum()\n",
    "    return p_new\n",
    "\n",
    "def kl_div(p_new, p_old):\n",
    "    eps = 1e-12\n",
    "    p = np.clip(p_new, eps, 1.0)\n",
    "    q = np.clip(p_old, eps, 1.0)\n",
    "    return float(np.sum(p*(np.log(p)-np.log(q))))\n",
    "\n",
    "p = p0.copy()\n",
    "history = {\"iter\": [], \"obj\": [], \"rtp\": [], \"hit\": [], \"var\": [], \"kl\": []}\n",
    "lr = 0.4\n",
    "for t in range(600):\n",
    "    obj, grad, rtp, hit, var = objective_and_grad(p)\n",
    "    history[\"iter\"].append(t); history[\"obj\"].append(obj)\n",
    "    history[\"rtp\"].append(rtp); history[\"hit\"].append(hit); history[\"var\"].append(var)\n",
    "    p_new = md_step(p, grad, lr)\n",
    "    history[\"kl\"].append(kl_div(p_new, p))\n",
    "    p = p_new\n",
    "    # quick guardrail nudges\n",
    "    rtp, hit, var = metrics(p)\n",
    "    if rtp < rtp_target - rtp_tol or rtp > rtp_target + rtp_tol or hit < hit_target - hit_tol or hit > hit_target + hit_tol:\n",
    "        p = np.maximum(p, 1e-12); p = p/ p.sum()\n",
    "        miss_idx = 0; small_win_idx = int(np.where(payouts>0)[0][0])\n",
    "        if abs(hit - hit_target) > 1e-4:\n",
    "            step = np.clip(0.0005*np.sign(hit_target-hit), -p[small_win_idx]+1e-12, p[miss_idx]-1e-12)\n",
    "            p[miss_idx] -= step; p[small_win_idx] += step\n",
    "        rtp, hit, var = metrics(p)\n",
    "        low_idx = int(np.where(payouts==1)[0][0]); high_idx = int(np.where(payouts==10)[0][0])\n",
    "        if abs(rtp - rtp_target) > 1e-4:\n",
    "            step = np.clip(0.0005*np.sign(rtp_target-rtp), -p[high_idx]+1e-12, p[low_idx]-1e-12)\n",
    "            p[low_idx] -= step; p[high_idx] += step\n",
    "        p = np.maximum(p, 1e-12); p = p / p.sum()\n",
    "rtp_f, hit_f, var_f = metrics(p)\n",
    "rtp0, hit0, var0, rtp_f, hit_f, var_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "hist_df = pd.DataFrame(history)\n",
    "plt.figure(); plt.plot(hist_df[\"iter\"], hist_df[\"obj\"]); plt.title(\"Objective\"); plt.xlabel(\"iter\"); plt.ylabel(\"obj\"); plt.show()\n",
    "plt.figure(); \n",
    "plt.plot(hist_df[\"iter\"], hist_df[\"rtp\"], label=\"RTP\"); \n",
    "plt.plot(hist_df[\"iter\"], hist_df[\"hit\"], label=\"Hit\"); \n",
    "plt.plot(hist_df[\"iter\"], hist_df[\"var\"], label=\"Var\"); \n",
    "plt.legend(); plt.title(\"Metrics\"); plt.xlabel(\"iter\"); plt.ylabel(\"value\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006af2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo\n",
    "N = 1_000_000\n",
    "samples = np.random.choice(len(payouts), size=N, p=p)\n",
    "returns = payouts[samples]\n",
    "mc_rtp, mc_hit, mc_var = float(returns.mean()), float((returns>0).mean()), float(returns.var())\n",
    "mc_rtp, mc_hit, mc_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afbc27",
   "metadata": {},
   "source": [
    "**結果對齊**：解析與模擬數值接近，即代表公式與實作一致。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
